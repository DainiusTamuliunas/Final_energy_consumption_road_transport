{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhqu6cDFzANE4MQwZoDCpN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGxjwuwBWASP","executionInfo":{"status":"ok","timestamp":1729154400086,"user_tz":-180,"elapsed":11208,"user":{"displayName":"Dainius TamuliÅ«nas","userId":"04370657899948480821"}},"outputId":"96c70ab5-f1b1-4db4-fa4b-ad1604ddc85d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# Mount Google Drive for saving the output file\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Initialize an empty DataFrame to store the combined results\n","combined_df = pd.DataFrame()\n","\n","# Function to check if there is a second page and get the link to it\n","def has_next_page(soup):\n","    \"\"\"\n","    Checks if the webpage has a link to a second page.\n","\n","    :param soup: Parsed HTML content of the webpage.\n","    :return: True if there is a second page, False otherwise.\n","    \"\"\"\n","    pagination_links = soup.find_all('a', string='Go to Page 2')\n","    return len(pagination_links) > 0\n","\n","# Loop through all the years from 1934 to 2017\n","for year in range(1934, 2018):\n","    # Loop through the pages for a year (first page is '', second page is 'b')\n","    page_suffixes = ['', 'b']  # Page 1 is '', Page 2 is 'b'\n","    for page_suffix in page_suffixes:\n","        # URL of the webpage to scrape for the specific year and page\n","        url = f\"https://www.totalmotorcycle.com/MotorcycleFuelEconomyGuide/{year}{page_suffix}-MPG?d=1\"\n","\n","        # Send an HTTP request to the webpage\n","        response = requests.get(url)\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","\n","        # Locate the table using the specified selector or fallback method\n","        table = soup.select_one('#Layer3 > div:nth-child(8) > table')\n","        if not table:\n","            table = soup.find('table', {'border': '4'})\n","\n","        # If table is still not found, skip this page\n","        if not table:\n","            print(f\"Table not found for year {year}{page_suffix}, skipping...\")\n","            continue\n","\n","        # Extract the table headers and rows\n","        headers = [th.get_text(strip=True) for th in table.find_all('th')]\n","        rows = []\n","        for row in table.find_all('tr'):\n","            cols = [col.get_text(strip=True) for col in row.find_all(['td', 'th'])]\n","            rows.append(cols)\n","\n","        # Convert the data to a pandas DataFrame\n","        df_year = pd.DataFrame(rows[1:], columns=rows[0])\n","\n","        # Add a new column for the year and page\n","        df_year['Year'] = f\"{year}{page_suffix}\"\n","\n","        # Append the DataFrame for this year and page to the combined DataFrame\n","        combined_df = pd.concat([combined_df, df_year], ignore_index=True)\n","\n","        # Check if there's a second page\n","        if page_suffix == '' and not has_next_page(soup):\n","            # If there is no second page, break the loop and move to the next year\n","            break\n","\n","# Remove duplicate rows from the combined DataFrame\n","combined_df.drop_duplicates(inplace=True)\n","\n","# File Path for saving the output\n","file_path = '/content/drive/MyDrive/Master Paper/Data/'\n","\n","# Save the combined DataFrame to a CSV file\n","output_file = file_path + 'motorcycle_fuel_economy_1934_to_2017.csv'\n","combined_df.to_csv(output_file, index=False)\n","\n","print(f\"Data saved to {output_file}\")\n","\n","# Rename columns to meaningful Lithuanian names\n","combined_df = combined_df.rename(columns={\n","    'Year': 'metai',\n","    'Manufacturer': 'cleaned_marke',\n","    'Model': 'modelis',\n","    'Engine Size (cc) /Cyl': 'variklio_turis_ir_cilindrai',\n","    'Average MPG': 'vidutines_mpg',\n","    'Average L/100km': 'vidutines_l_100km',\n","    'Source': 'saltinis'\n","})\n","\n","# Split the 'variklio_turis_ir_cilindrai' column into 'variklio_turis_cm3' and 'cilindrai'\n","combined_df[['variklio_turis_cm3', 'cilindrai']] = combined_df['variklio_turis_ir_cilindrai'].str.split('/', expand=True)\n","\n","# Clean up fuel consumption columns by removing units\n","combined_df['vidutines_l_100km'] = combined_df['vidutines_l_100km'].str.replace(' L/100km', '', regex=False)\n","combined_df['vidutines_mpg'] = combined_df['vidutines_mpg'].str.replace(' MPG', '', regex=False)\n","\n","# Drop the original 'variklio_turis_ir_cilindrai' column as it's no longer needed\n","combined_df = combined_df.drop(columns=['variklio_turis_ir_cilindrai', 'Engine Siz(cc) /Cyl'])\n","\n","# Save the cleaned combined DataFrame to a CSV file\n","output_file = file_path + 'moto_makers_models_fuel_consumptions_cleaned.csv'\n","combined_df.to_csv(output_file, index=False)\n","\n","print(f\"Cleaned data saved to {output_file}\")\n","# Display the cleaned DataFrame\n","print(combined_df.head())\n","\n"]}]}